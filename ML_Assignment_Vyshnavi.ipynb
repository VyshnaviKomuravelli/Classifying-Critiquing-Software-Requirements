{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Model for Classifying & Critiquing Software Requirements"
      ],
      "metadata": {
        "id": "5AX6r_nWUlsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required libraries (Install if any package is not present)"
      ],
      "metadata": {
        "id": "gjKqZzG8v4AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noNQM7OEYWf4",
        "outputId": "f33f977a-ef9f-4b30-9a69-c85006bb1ecb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MAaPh0-l1xqo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "import fasttext\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW,  Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "a6hdG5jmwGNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjmSAd64ZEJl",
        "outputId": "92c22ec1-a91a-4313-9528-7b61a6779dad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_preprocess_data(file_path1, file_path2):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from two CSV files, then combine them into a single DataFrame.\n",
        "\n",
        "    Args:\n",
        "        file_path1 (str): Path to the first CSV file.\n",
        "        file_path2 (str): Path to the second CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Combined and preprocessed DataFrame.\n",
        "    \"\"\"\n",
        "    # Load data from CSV files\n",
        "    data1 = pd.read_csv(file_path1)\n",
        "    data2 = pd.read_csv(file_path2)\n",
        "\n",
        "    # Select relevant columns and rename them for consistency\n",
        "    data1 = data1[['Label', 'Document']]\n",
        "    data1 = data1.rename(columns={'Label': 'Type', 'Document': 'Requirement'})\n",
        "\n",
        "    # Concatenate the two datasets and remove duplicates\n",
        "    df = pd.concat([data1, data2])\n",
        "    df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # Standardize the 'Type' column\n",
        "    df['Type'] = df['Type'].apply(lambda x: 'F' if x in ['F', 'FR'] else ('UX' if x in ['LF', 'US'] else 'NFR'))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "file_path1 = '/content/drive/MyDrive/MLassignment-Vyshnavi/nfr.csv'\n",
        "file_path2 = '/content/drive/MyDrive/MLassignment-Vyshnavi/software_requirements_extended.csv'\n",
        "df = load_and_preprocess_data(file_path1, file_path2)\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6zjxbm_w3D2e",
        "outputId": "b784bd07-0133-4dfc-fa2d-7ee5ed240001"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Type                                        Requirement\n",
              "0     NFR  The system shall refresh the display every 60 ...\n",
              "1      UX  The application shall match the color of the s...\n",
              "2      UX   If projected  the data must be readable.  On ...\n",
              "3     NFR   The product shall be available during normal ...\n",
              "4      UX   If projected  the data must be understandable...\n",
              "...   ...                                                ...\n",
              "1004    F  There will be a designated phone number that u...\n",
              "1005    F  Texts sent to that number will be sent to the ...\n",
              "1006    F  If a question is not understood by our API, th...\n",
              "1007    F  Upon the USB being plugged in the system shall...\n",
              "1008    F  The system shall be able to handle 1000 custom...\n",
              "\n",
              "[1009 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd124fe3-68d8-4b00-986e-6d47481dfbb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Requirement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NFR</td>\n",
              "      <td>The system shall refresh the display every 60 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UX</td>\n",
              "      <td>The application shall match the color of the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UX</td>\n",
              "      <td>If projected  the data must be readable.  On ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NFR</td>\n",
              "      <td>The product shall be available during normal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UX</td>\n",
              "      <td>If projected  the data must be understandable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>F</td>\n",
              "      <td>There will be a designated phone number that u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>F</td>\n",
              "      <td>Texts sent to that number will be sent to the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>F</td>\n",
              "      <td>If a question is not understood by our API, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>F</td>\n",
              "      <td>Upon the USB being plugged in the system shall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>F</td>\n",
              "      <td>The system shall be able to handle 1000 custom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1009 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd124fe3-68d8-4b00-986e-6d47481dfbb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd124fe3-68d8-4b00-986e-6d47481dfbb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd124fe3-68d8-4b00-986e-6d47481dfbb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec9db38b-83f6-4bbe-841d-ec424a8bb543\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec9db38b-83f6-4bbe-841d-ec424a8bb543')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec9db38b-83f6-4bbe-841d-ec424a8bb543 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a924f5b4-fc93-4a09-8d7c-ab378b2e1e1f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a924f5b4-fc93-4a09-8d7c-ab378b2e1e1f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1009,\n  \"fields\": [\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NFR\",\n          \"UX\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Requirement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1008,\n        \"samples\": [\n          \"Edit an existing user\\u00e2\\u20ac\\u2122s information Given the administrator is logged in When the administrator edits an existing user Then the user information should be updated\",\n          \"the user can approve the exchange that is offered by another user by clicking\\n\\u201cApprove\\u201d button.\",\n          \"All layout shall be according to the TU/e corporate identity, unless in conflict with the guidelines of requirements UCOR003-UCOR006.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the number of occurrences of each unique value in the 'Type' column."
      ],
      "metadata": {
        "id": "ACY9kATVxHuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This provides a quick overview of the distribution of different requirement types in the dataset.\n",
        "df['Type'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIMJwCCj3Lma",
        "outputId": "185cb7e2-ee25-4cc8-d2e3-d480ee93f3e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Type\n",
              "F      525\n",
              "NFR    380\n",
              "UX     104\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download necessary NLTK resources"
      ],
      "metadata": {
        "id": "3wqSLSN3xbDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_nltk_resources():\n",
        "    \"\"\"\n",
        "    Download necessary NLTK resources for text preprocessing:\n",
        "\n",
        "    - 'punkt': Tokenizer that divides a text into a list of sentences or words.\n",
        "    - 'stopwords': Collection of common words (e.g., 'the', 'is', 'in') that are usually removed in text preprocessing.\n",
        "    - 'wordnet': Large lexical database of English, which can be used for finding synonyms, antonyms, and word definitions.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Call the function to download NLTK resources\n",
        "download_nltk_resources()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_dYa1aQ58jZ",
        "outputId": "d662affa-c6f0-4f87-eea2-92c0506e3349"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning: Text Preprocessing"
      ],
      "metadata": {
        "id": "DPP3jn8dyBRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans the input text by performing the following steps:\n",
        "\n",
        "    1. Converts the text to lowercase.\n",
        "    2. Removes punctuation and special characters.\n",
        "    3. Tokenizes the text into individual words.\n",
        "    4. Removes stop words and lemmatizes the remaining words.\n",
        "    5. Joins the cleaned tokens back into a single string.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned text.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words and lemmatize\n",
        "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join tokens back into a single string\n",
        "    cleaned_text = ' '.join(cleaned_tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the cleaning function to the 'Requirement' column\n",
        "df['Cleaned_Requirement'] = df['Requirement'].apply(clean_text)\n",
        "\n",
        "# Print cleaned data for verification\n",
        "print(df[['Type', 'Cleaned_Requirement']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVIcXt1d7UfX",
        "outputId": "00db87cb-a5bd-4701-eb35-78b1cc4e01fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Type                                Cleaned_Requirement\n",
            "0     NFR          system shall refresh display every second\n",
            "1      UX  application shall match color schema set forth...\n",
            "2      UX  projected data must readable x projection scre...\n",
            "3     NFR  product shall available normal business hour l...\n",
            "4      UX  projected data must understandable x projectio...\n",
            "...   ...                                                ...\n",
            "1004    F             designated phone number user send text\n",
            "1005    F  text sent number sent api system reply user an...\n",
            "1006    F  question understood api system send text conta...\n",
            "1007    F  upon usb plugged system shall able deployed op...\n",
            "1008    F  system shall able handle customer logged concu...\n",
            "\n",
            "[1009 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Train Test splits"
      ],
      "metadata": {
        "id": "04HMivHsyZPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Requirement'], df['Type'], test_size=0.3, random_state=42,stratify=df['Type'])\n",
        "print(y_train.value_counts(),y_test.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlzAkqC1ABNa",
        "outputId": "d2babc7b-e030-4687-b851-1f33e8d930c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type\n",
            "F      367\n",
            "NFR    266\n",
            "UX      73\n",
            "Name: count, dtype: int64 Type\n",
            "F      158\n",
            "NFR    114\n",
            "UX      31\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "y4mbNVyWY1Wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Off-the-Shelf Models"
      ],
      "metadata": {
        "id": "Qs6qmIP2uWYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Model Fine-Tuning and Classification\n",
        "\n",
        "#### Split Data\n",
        "- Split the data into training and testing sets.\n",
        "\n",
        "#### Load BERT Model and Tokenizer\n",
        "- Load the pre-trained BERT model and tokenizer for sequence classification with 3 output classes: F, NFR, UX.\n",
        "\n",
        "#### Tokenize Text Data\n",
        "- Tokenize the text data for both training and testing sets, padding sequences to a max length of 128.\n",
        "\n",
        "#### Convert Labels to Integers\n",
        "- Convert the labels to integers using a label map.\n",
        "\n",
        "#### Create DataLoader\n",
        "- Create DataLoader for both training and testing sets.\n",
        "\n",
        "#### Fine-Tune BERT Model\n",
        "- Fine-tune the BERT model on the training set for 10 epochs.\n",
        "\n",
        "#### Evaluate the Fine-Tuned Model\n",
        "- Evaluate the fine-tuned model on the testing set and collect predictions and true labels.\n",
        "\n",
        "#### Results\n",
        "- Print the accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "Et1kzrwO3122"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Requirement'], df['Type'], test_size=0.3, random_state=5, stratify=df['Type'])\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # 3 output classes: F, NFR, UX\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize text data\n",
        "X_train_tokenized = tokenizer(list(X_train), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "X_test_tokenized = tokenizer(list(X_test), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Convert labels to integers\n",
        "label_map = {label: i for i, label in enumerate(df['Type'].unique())}\n",
        "y_train_encoded = torch.tensor([label_map[label] for label in y_train])\n",
        "y_test_encoded = torch.tensor([label_map[label] for label in y_test])\n",
        "\n",
        "# Create DataLoader for training and testing sets\n",
        "train_dataset = TensorDataset(X_train_tokenized['input_ids'], X_train_tokenized['attention_mask'], y_train_encoded)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_dataset = TensorDataset(X_test_tokenized['input_ids'], X_test_tokenized['attention_mask'], y_test_encoded)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# Fine-tune the BERT model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(torch.argmax(logits, axis=1).cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXinvWXwUDNH",
        "outputId": "63fa5bed-364f-4e30-c12d-ec081641a2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = [label_map[label] for label in y_test]\n",
        "# Convert integer labels back to original labels\n",
        "label_map_inverse = {0: 'NFR', 1: 'UX', 2: 'F'}\n",
        "predicted_labels = [label_map_inverse[label] for label in predictions]\n",
        "true_labels = [label_map_inverse[label] for label in test_labels]\n",
        "\n",
        "# Save the fine-tuned BERT model\n",
        "model.save_pretrained(\"fine_tuned_bert_model\")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"fine_tuned_bert_model/tokenizer\")\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(true_labels, predicted_labels, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=['F', 'NFR', 'UX'])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "-B8bnEK1UOPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b22b16-fb13-4369-a92a-74d845499cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.11%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.92      0.89      0.90       158\n",
            "         NFR       0.85      0.89      0.87       114\n",
            "          UX       0.93      0.87      0.90        31\n",
            "\n",
            "    accuracy                           0.89       303\n",
            "   macro avg       0.90      0.89      0.89       303\n",
            "weighted avg       0.89      0.89      0.89       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[141  16   1]\n",
            " [ 11 102   1]\n",
            " [  2   2  27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom model training"
      ],
      "metadata": {
        "id": "m5HalZ86Zbkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fasttext Model Training\n"
      ],
      "metadata": {
        "id": "7B1dbE3z1v7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Requirement'], df['Type'], test_size=0.3, random_state=5, stratify=df['Type'])\n",
        "# Prepare training data in fastText format\n",
        "X_train_array = np.array(X_train)\n",
        "X_train_flattened = X_train_array.flatten()\n",
        "train_data_fasttext = []\n",
        "for text, label in zip(X_train_flattened, y_train):\n",
        "    train_data_fasttext.append(f\"__label__{label} {text}\")\n",
        "\n",
        "# Write the training data to a file\n",
        "with open('train_data.txt', 'w') as f:\n",
        "    for item in train_data_fasttext:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "# Train the fastText model\n",
        "\n",
        "model = fasttext.train_supervised(input='train_data.txt', epoch=100, lr=0.1, wordNgrams=2)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = [model.predict(text)[0][0].split('__label__')[1] for text in X_test]\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_4il9Rk95Ej",
        "outputId": "b2944d15-8c38-4522-e4e5-d980c56e30d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.14%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.87      0.92      0.90       158\n",
            "         NFR       0.84      0.88      0.86       114\n",
            "          UX       0.88      0.48      0.62        31\n",
            "\n",
            "    accuracy                           0.86       303\n",
            "   macro avg       0.87      0.76      0.79       303\n",
            "weighted avg       0.86      0.86      0.86       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[146  11   1]\n",
            " [ 13 100   1]\n",
            " [  8   8  15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Model Training and Classification with Doc2Vec\n",
        "\n",
        "#### Define Parameter Grid\n",
        "- Define a parameter grid for GridSearchCV to optimize hyperparameters for SVM.\n",
        "\n",
        "#### Split Data and Train SVM Model\n",
        "- Split the data into training and testing sets.\n",
        "- Perform GridSearchCV to find the best hyperparameters for SVM.\n",
        "\n",
        "#### Save the Trained Model\n",
        "- Save the trained SVM model using joblib.\n",
        "\n",
        "#### Make Predictions and Evaluate Model\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "#### Results\n",
        "- Print the best parameters found by GridSearchCV, best cross-validation score, accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "EgOfG_t-0zKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "tagged_documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['Cleaned_Requirement'])]\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Memory (DM)\n",
        "model_dm = Doc2Vec(vector_size=20, window=4, min_count=1, workers=4, epochs=100, dm=1)\n",
        "model_dm.build_vocab(tagged_documents)\n",
        "model_dm.train(tagged_documents, total_examples=model_dm.corpus_count, epochs=model_dm.epochs)\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Bag of Words (DBOW)\n",
        "model_dbow = Doc2Vec(vector_size=20, window=2, min_count=1, workers=4, epochs=100, dm=0)\n",
        "model_dbow.build_vocab(tagged_documents)\n",
        "model_dbow.train(tagged_documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
        "\n",
        "# Transform documents into vectors using both trained Doc2Vec models\n",
        "document_vectors_dm = [model_dm.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "document_vectors_dbow = [model_dbow.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "\n",
        "# Concatenate the vectors from both models\n",
        "document_vectors_combined = [list(dm_vec) + list(dbow_vec) for dm_vec, dbow_vec in zip(document_vectors_dm, document_vectors_dbow)]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(document_vectors_combined, df['Type'], random_state=10, test_size=0.3,stratify=df['Type'])\n",
        "\n",
        "grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "# Make predictions on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "\n",
        "joblib.dump(grid_search, \"svm_model.pkl\")\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Combined DM and DBOW Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-mxyfG33Fhs",
        "outputId": "cc5676fa-3cae-47f7-af14-d02179ce3119"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Best cross-validation score: 0.798851263610029\n",
            "Combined DM and DBOW Accuracy: 82.18%\n",
            "Accuracy: 0.8217821782178217\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.83      0.91      0.86       158\n",
            "         NFR       0.82      0.76      0.79       114\n",
            "          UX       0.79      0.61      0.69        31\n",
            "\n",
            "    accuracy                           0.82       303\n",
            "   macro avg       0.81      0.76      0.78       303\n",
            "weighted avg       0.82      0.82      0.82       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[143  12   3]\n",
            " [ 25  87   2]\n",
            " [  5   7  19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the BERT model is performing well in predicting three types of software requirements, achieving an accuracy of 89%."
      ],
      "metadata": {
        "id": "XXOAtDv8WU_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "#### Compare the performance of custom models and off-the-shelf models\n",
        "\n",
        "For this project, both custom and off-the-shelf models were explored to predict software requirements accurately. The custom models included a variety of techniques such as SVM, logistic regression, Naive Bayes, LSTM, TF-IDF, Doc2Vec, and BOW. In contrast, the off-the-shelf models considered was BERT.\n",
        "\n",
        "Among the custom models, fasttext showed notable performance. This combination leveraged the strengths of tasttext for classification and, resulting in satisfactory predictions.\n",
        "\n",
        "For off-the-shelf models, BERT emerged as the top performer. BERT, with its deep learning architecture and pre-trained language model capabilities, provided superior performance in understanding the context and nuances of the software requirements.\n",
        "\n",
        "#### Select the best-performing model based on evaluation metrics\n",
        "\n",
        "After a thorough comparison, BERT was identified as the best-performing model overall. It excelled in predicting all types of software requirements with an impressive accuracy of 89.11%. The comprehensive evaluation metrics further highlighted BERT's effectiveness.\n",
        "\n",
        "**Evaluation Metrics:**\n",
        "\n",
        "**Accuracy:** 89.11%\n",
        "\n",
        "**Classification Report:**\n",
        "\n",
        "          precision    recall  f1-score   support\n",
        "\n",
        "    F       0.92      0.89      0.90       158\n",
        "    NFR     0.85      0.89      0.87       114\n",
        "    UX      0.93      0.87      0.90        31\n",
        "\n",
        "accuracy    -                       0.89       \n",
        "\n"
      ],
      "metadata": {
        "id": "im_xIMZzXUrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Feedback for Software Requirements\n",
        "\n",
        "This code uses OpenAI's GPT-3.5-turbo model to generate feedback for software requirements. It takes a requirement and its label as input and provides constructive feedback, suggestions for improvement, identifies potential issues, or seeks clarification if needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "JQaAlnCM4X-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = 'sk-proj-x1jqzAcp5BOnYCfM3EQJT3BlbkFJNl9PwbgwNSGKZ7mppBDD'\n",
        "\n",
        "def generate_feedback(requirement, label):\n",
        "    input_text = f\"Requirement: {requirement}\\nLabel: {label}\\nFeedback: Provide suggestions for improvement, identify any issues, or clarify if needed.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in software requirements and user experience. Provide constructive feedback for the given requirement.\"},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=1\n",
        "    )\n",
        "\n",
        "    feedback = response.choices[0].message[\"content\"].strip()\n",
        "    return feedback\n",
        "\n",
        "# Example usage\n",
        "a = generate_feedback(\"The product shall be intuitive and self-explanatory\", \"User Experience\")\n",
        "print(a)\n"
      ],
      "metadata": {
        "id": "wC037FyOPCkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688dc0b6-b2cc-4567-c954-dd7de37eefc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This requirement is a good starting point for ensuring a positive user experience, but it lacks specific details on how the product will achieve being intuitive and self-explanatory. To make this requirement more effective, consider adding measurable criteria or examples to clarify what \"intuitive\" means in the context of the product. \n",
            "\n",
            "For example, you could define specific user actions that should be straightforward with minimal guidance, or include target metrics for user onboarding success rates. Additionally, consider involving actual users in the testing or design process to gather feedback on whether the product meets their expectations for intuitiveness and self-explanatory features. This approach will help ensure that the user experience is truly intuitive and satisfying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification and Feedback Generation"
      ],
      "metadata": {
        "id": "HovAGEq442Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load the fine-tuned BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('fine_tuned_bert_model')\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('fine_tuned_bert_model/tokenizer')\n",
        "\n",
        "# Example usage\n",
        "sentence = \"The product shall be intuitive and self-explanatory.\"\n",
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "predicted_label_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "predicted_label = model.config.id2label[predicted_label_id]\n",
        "label_map = {'LABEL_0': 'NFR', 'LABEL_1': 'UX', 'LABEL_2': 'F'}\n",
        "# print(f\"Predicted Label: {label_map[predicted_label]}\")\n",
        "\n",
        "type_map = {'NFR': 'Non functional requirement', 'UX': 'User Experience', 'F': 'Functional requirement'}\n",
        "label=label_map[predicted_label]\n",
        "print(f\"Predicted Label: {type_map[label]}({label_map[predicted_label]})\")\n",
        "# Generate feedback\n",
        "a = generate_feedback(sentence, type_map[label])\n",
        "print(f\"Feedback: {a}\")"
      ],
      "metadata": {
        "id": "8SOhatz4SFuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8284195b-6131-40d6-81ad-0955caf42cd2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: User Experience(UX)\n",
            "Feedback: Feedback:\n",
            "1. Define what \"intuitive and self-explanatory\" means in the context of your product. What specific actions, features, or elements should be intuitive for users? \n",
            "2. Consider conducting user testing or user research to validate if the product is indeed intuitive and self-explanatory for your target users. \n",
            "3. Provide clear onboarding instructions or tooltips to guide users through the product, especially for complex or new features. \n",
            "4. Use consistent design patterns and language throughout the product to enhance usability and familiarity for users. \n",
            "5. Seek feedback from users regularly to identify any areas of improvement in the product's intuitiveness and self-explanatory nature. \n",
            "6. Continuously iterate and refine the user experience based on user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The product shall be available 99% of the time. Rationale\"\n",
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "predicted_label_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "predicted_label = model.config.id2label[predicted_label_id]\n",
        "label_map = {'LABEL_0': 'NFR', 'LABEL_1': 'UX', 'LABEL_2': 'F'}\n",
        "# print(f\"Predicted Label: {label_map[predicted_label]}\")\n",
        "\n",
        "type_map = {'NFR': 'Non functional requirement', 'UX': 'User Experience', 'F': 'Functional requirement'}\n",
        "label=label_map[predicted_label]\n",
        "print(f\"Predicted Label: {type_map[label]}({label_map[predicted_label]})\")\n",
        "# Generate feedback\n",
        "a = generate_feedback(sentence, type_map[label])\n",
        "print(f\"Feedback: {a}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YharIIKYGqO4",
        "outputId": "8729ae77-845c-4195-dc4e-43a5d9d564bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Non functional requirement(NFR)\n",
            "Feedback: Feedback:\n",
            "1. Define what \"availability\" means here - Does it mean the system is accessible to users or fully functional during that time?\n",
            "2. Specify whether this availability target includes planned maintenance periods or only unexpected downtime.\n",
            "3. Consider including performance metrics such as response time or uptime percentage in addition to availability.\n",
            "4. Ensure that this requirement aligns with business needs and user expectations - 99% availability might be too low for critical applications.\n",
            "5. Consider adding a contingency plan in case the requirement is not met, such as notifying users or providing alternative access during downtime.\n",
            "6. Consider defining how availability will be measured and monitored to ensure this requirement is met consistently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"A search described in requirement UCAR602 results in a displayed set of topics.\"\n",
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "predicted_label_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "predicted_label = model.config.id2label[predicted_label_id]\n",
        "label_map = {'LABEL_0': 'NFR', 'LABEL_1': 'UX', 'LABEL_2': 'F'}\n",
        "# print(f\"Predicted Label: {label_map[predicted_label]}\")\n",
        "\n",
        "type_map = {'NFR': 'Non functional requirement', 'UX': 'User Experience', 'F': 'Functional requirement'}\n",
        "label=label_map[predicted_label]\n",
        "print(f\"Predicted Label: {type_map[label]}({label_map[predicted_label]})\")\n",
        "# Generate feedback\n",
        "a = generate_feedback(sentence, type_map[label])\n",
        "print(f\"Feedback: {a}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ysYDobHCjE",
        "outputId": "726110c7-21f9-4b7a-e0a0-09c1d7853cd3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Functional requirement(F)\n",
            "Feedback: Feedback:\n",
            "1. The requirement is quite vague and lacks specificity. It would be helpful to define what \"search\" involves - such as what can be searched for, where the search takes place, and what filters or options are available to the user.\n",
            "2. It would be beneficial to clarify the expected scope and contents of the \"set of topics\" that are displayed as a result of the search. Are these topics related to the search query, sorted in a specific order, or selected based on some criteria?\n",
            "3. Consider incorporating information on how users can interact with the displayed topics – for example, can they filter, sort, or further explore these topics?\n",
            "4. Ensure that the requirement aligns with user needs and expectations, and that it contributes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "Ie69p_N86fQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the analysis conducted in this notebook, the best results were achieved using the BERT-based model for classifying software requirements into functional (F), non-functional (NFR), and user experience (UX) categories. The BERT model outperformed other models such as SVM, fasttext, LSTM, Naive bayes in terms of accuracy and overall performance.\n",
        "\n",
        "The BERT model demonstrated superior performance due to its ability to capture contextual information and semantic meaning effectively, especially for the complex and varied language found in software requirements. By leveraging pre-trained language representations, BERT was able to understand the nuances of the requirements and classify them accurately.\n",
        "\n",
        "Additionally, the BERT model benefited from fine-tuning on the specific classification task, which further improved its performance. The fine-tuning process allowed the model to adapt to the nuances of the dataset, resulting in better classification accuracy.\n",
        "\n",
        "In conclusion, the BERT-based model proved to be the most effective for classifying software requirements in this analysis, showcasing its capabilities in natural language understanding and classification tasks. And feedback is generated for the software requirements."
      ],
      "metadata": {
        "id": "sgioDZpN7INr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wpyovsV-45G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Experiments with Custom models"
      ],
      "metadata": {
        "id": "jTSzrJ0C7JlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model Training and Classification with Tokenization\n",
        "\n",
        "#### Tokenization\n",
        "- Tokenize the cleaned requirements with a limit of 10,000 words.\n",
        "- Convert the tokenized sequences to sequences of integers.\n",
        "- Pad the sequences to ensure uniform length.\n",
        "\n",
        "#### Split Data and Convert Labels\n",
        "- Split the data into training and testing sets.\n",
        "- Convert labels to integers using LabelEncoder.\n",
        "\n",
        "#### Build and Compile LSTM Model\n",
        "- Build an LSTM model with an embedding layer, LSTM layer, and dense softmax layer.\n",
        "- Compile the model using 'adam' optimizer and 'sparse_categorical_crossentropy' loss.\n",
        "\n",
        "#### Train the Model\n",
        "- Train the model on the training data for 50 epochs with a batch size of 32.\n",
        "\n",
        "#### Make Predictions and Evaluate Model\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "#### Results\n",
        "- Print the accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "ZeB8HYTG2Zhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)  # Use the top 10,000 words\n",
        "tokenizer.fit_on_texts(df[\"Cleaned_Requirement\"])\n",
        "sequences = tokenizer.texts_to_sequences(df[\"Cleaned_Requirement\"])\n",
        "\n",
        "# Pad the sequences to ensure uniform length\n",
        "max_sequence_length = 20  # Choose a suitable maximum length for your data\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, df['Type'], test_size=0.3, stratify=df['Type'])\n",
        "\n",
        "# Convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_sequence_length))  # Adjust output_dim and input_length as needed\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2,activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 output classes: F, NFR, UX\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# Convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test_encoded, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test_encoded, y_pred, labels=[0, 1, 2])  # Use integer labels\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dMyUL66Abc0",
        "outputId": "4eabc57b-c649-4f7d-e432-562554b8d571"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 8s 99ms/step - loss: 1.0462 - accuracy: 0.4986 - val_loss: 0.9649 - val_accuracy: 0.5215\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.9110 - accuracy: 0.5241 - val_loss: 0.8558 - val_accuracy: 0.5446\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.7385 - accuracy: 0.6473 - val_loss: 0.6874 - val_accuracy: 0.7591\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 3s 111ms/step - loss: 0.4978 - accuracy: 0.8272 - val_loss: 0.5607 - val_accuracy: 0.7921\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 0.3776 - accuracy: 0.8626 - val_loss: 0.5581 - val_accuracy: 0.7789\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.2702 - accuracy: 0.8725 - val_loss: 0.5665 - val_accuracy: 0.7921\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.1770 - accuracy: 0.9193 - val_loss: 0.5578 - val_accuracy: 0.8020\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.1863 - accuracy: 0.9703 - val_loss: 0.5439 - val_accuracy: 0.8086\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0804 - accuracy: 0.9802 - val_loss: 0.8109 - val_accuracy: 0.8350\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0736 - accuracy: 0.9844 - val_loss: 0.5654 - val_accuracy: 0.7987\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0765 - accuracy: 0.9802 - val_loss: 0.5893 - val_accuracy: 0.8416\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 0.6569 - val_accuracy: 0.8350\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.0199 - accuracy: 0.9972 - val_loss: 0.9657 - val_accuracy: 0.8482\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0238 - accuracy: 0.9958 - val_loss: 0.6821 - val_accuracy: 0.8449\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0280 - accuracy: 0.9943 - val_loss: 1.1355 - val_accuracy: 0.8284\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.0610 - accuracy: 0.9901 - val_loss: 0.6160 - val_accuracy: 0.8218\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.0230 - accuracy: 0.9958 - val_loss: 0.8436 - val_accuracy: 0.8317\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 0.8050 - val_accuracy: 0.8317\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.7638 - val_accuracy: 0.8449\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.8476 - val_accuracy: 0.8416\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.2159 - accuracy: 0.9915 - val_loss: 0.5600 - val_accuracy: 0.8449\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.8219 - val_accuracy: 0.8350\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.7575 - val_accuracy: 0.8482\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0257 - accuracy: 0.9972 - val_loss: 0.6233 - val_accuracy: 0.8317\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 0.6562 - val_accuracy: 0.8284\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0137 - accuracy: 0.9986 - val_loss: 0.7742 - val_accuracy: 0.8218\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.8708 - val_accuracy: 0.8284\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.6962 - val_accuracy: 0.8218\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.8684 - val_accuracy: 0.8218\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.9600 - val_accuracy: 0.8317\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.7691 - val_accuracy: 0.8251\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.9699 - val_accuracy: 0.8251\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 1.0030 - val_accuracy: 0.8218\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 1.1065 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.7960 - val_accuracy: 0.8416\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.8436 - val_accuracy: 0.8317\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0086 - accuracy: 0.9958 - val_loss: 1.0246 - val_accuracy: 0.8383\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.5503 - val_accuracy: 0.8152\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0232 - accuracy: 0.9958 - val_loss: 0.8124 - val_accuracy: 0.8251\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 1.1528 - val_accuracy: 0.8218\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 1.2557 - val_accuracy: 0.8086\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 1.4776 - val_accuracy: 0.8152\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 1.6547 - val_accuracy: 0.8152\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.6108 - val_accuracy: 0.8119\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.0032 - accuracy: 0.9972 - val_loss: 1.6615 - val_accuracy: 0.8086\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 1.5713 - val_accuracy: 0.8152\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.6671 - val_accuracy: 0.8218\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.7414 - val_accuracy: 0.8218\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 1.8706 - val_accuracy: 0.8251\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 2.3918 - val_accuracy: 0.8284\n",
            "10/10 [==============================] - 0s 7ms/step\n",
            "Accuracy: 82.84%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.87      0.90      0.88       158\n",
            "         NFR       0.78      0.84      0.81       114\n",
            "          UX       0.76      0.42      0.54        31\n",
            "\n",
            "    accuracy                           0.83       303\n",
            "   macro avg       0.81      0.72      0.75       303\n",
            "weighted avg       0.83      0.83      0.82       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[142  16   0]\n",
            " [ 14  96   4]\n",
            " [  7  11  13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations: Although the accuracy is good, the model is not performing well for UX software requirements."
      ],
      "metadata": {
        "id": "3tIrcZrbU_sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a SVM Model with linear kernel using TF-IDF\n",
        "\n",
        "**Classification:**\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "7dVlMXKHzJY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a SVM model\n",
        "classifier = SVC(kernel='linear')\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"f1 score: {f1}\")\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8QPLwuh_X0U",
        "outputId": "17bae715-859f-4061-fcca-2703d0dcd461"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8316831683168316\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.85      0.92      0.88       158\n",
            "         NFR       0.79      0.82      0.80       114\n",
            "          UX       0.93      0.45      0.61        31\n",
            "\n",
            "    accuracy                           0.83       303\n",
            "   macro avg       0.86      0.73      0.76       303\n",
            "weighted avg       0.84      0.83      0.82       303\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a SVM model with linear kernel using BOW\n",
        "\n",
        "**Text Preprocessing:**\n",
        "- Convert text data to numerical features using BOW (Bag Of Words).\n",
        "- Train a SVM Model with linear kernel.\n",
        "\n",
        "**Classification:**\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7HQIyoHzax5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text data to numerical features using Bag-of-Words (CountVectorizer)\n",
        "bow_vectorizer = CountVectorizer()\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_test_bow = bow_vectorizer.transform(X_test)\n",
        "classifier = SVC(kernel='linear')\n",
        "classifier.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_bow)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID1Y4BwyaG_A",
        "outputId": "6671e58d-330d-4eec-9137-865191d02f9e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8085808580858086\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.85      0.91      0.88       158\n",
            "         NFR       0.78      0.75      0.76       114\n",
            "          UX       0.65      0.55      0.60        31\n",
            "\n",
            "    accuracy                           0.81       303\n",
            "   macro avg       0.76      0.73      0.75       303\n",
            "weighted avg       0.80      0.81      0.81       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[143  15   0]\n",
            " [ 20  85   9]\n",
            " [  5   9  17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doc2Vec Model Training and Classification using Logistic Regression\n",
        "\n",
        "#### Tag Documents for Doc2Vec\n",
        "- Tag documents with indices for training.\n",
        "\n",
        "#### Initialize and Train Doc2Vec Models\n",
        "- Initialize and train two Doc2Vec models: Distributed Memory (DM) and Distributed Bag of Words (DBOW).\n",
        "\n",
        "#### Transform Documents into Vectors\n",
        "- Transform documents into vectors using both trained Doc2Vec models.\n",
        "\n",
        "#### Concatenate Vectors\n",
        "- Concatenate the vectors from both models.\n",
        "\n",
        "#### Split Data and Train Logistic Regression Model\n",
        "- Split the data into training and testing sets.\n",
        "- Initialize and train a logistic regression model.\n",
        "\n",
        "#### Make Predictions and Evaluate Model\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "#### Results\n",
        "- Print the accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "snkpjcWQz3jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag documents for Doc2Vec\n",
        "tagged_documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['Cleaned_Requirement'])]\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Memory (DM)\n",
        "model_dm = Doc2Vec(vector_size=20, window=4, min_count=1, workers=4, epochs=100, dm=1)\n",
        "model_dm.build_vocab(tagged_documents)\n",
        "model_dm.train(tagged_documents, total_examples=model_dm.corpus_count, epochs=model_dm.epochs)\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Bag of Words (DBOW)\n",
        "model_dbow = Doc2Vec(vector_size=20, window=2, min_count=1, workers=4, epochs=100, dm=0)\n",
        "model_dbow.build_vocab(tagged_documents)\n",
        "model_dbow.train(tagged_documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
        "\n",
        "# Transform documents into vectors using both trained Doc2Vec models\n",
        "document_vectors_dm = [model_dm.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "document_vectors_dbow = [model_dbow.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "\n",
        "# Concatenate the vectors from both models\n",
        "document_vectors_combined = [list(dm_vec) + list(dbow_vec) for dm_vec, dbow_vec in zip(document_vectors_dm, document_vectors_dbow)]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(document_vectors_combined, df['Type'], test_size=0.2,stratify=df['Type'])\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Combined DM and DBOW Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjIdrgKhe-kE",
        "outputId": "fcc4f928-2317-4c27-9660-2f3ff78a7b8e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DM and DBOW Accuracy: 76.24%\n",
            "Accuracy: 0.7623762376237624\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.80      0.90      0.85       105\n",
            "         NFR       0.77      0.67      0.72        76\n",
            "          UX       0.47      0.43      0.45        21\n",
            "\n",
            "    accuracy                           0.76       202\n",
            "   macro avg       0.68      0.66      0.67       202\n",
            "weighted avg       0.76      0.76      0.76       202\n",
            "\n",
            "Confusion Matrix:\n",
            "[[94  7  4]\n",
            " [19 51  6]\n",
            " [ 4  8  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doc2Vec Model Training and Classification using SVM with rbf kernel\n",
        "\n",
        "#### Tag Documents for Doc2Vec\n",
        "- Tag documents with indices for training.\n",
        "\n",
        "#### Initialize and Train Doc2Vec Models\n",
        "- Initialize and train two Doc2Vec models: Distributed Memory (DM) and Distributed Bag of Words (DBOW).\n",
        "\n",
        "#### Transform Documents into Vectors\n",
        "- Transform documents into vectors using both trained Doc2Vec models.\n",
        "\n",
        "#### Concatenate Vectors\n",
        "- Concatenate the vectors from both models.\n",
        "\n",
        "#### Split Data and Train SVM Model\n",
        "- Split the data into training and testing sets.\n",
        "- Initialize and train a SVM model with rbf kernel.\n",
        "\n",
        "#### Make Predictions and Evaluate Model\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "#### Results\n",
        "- Print the accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "hLbTFo7p0F6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag documents for Doc2Vec\n",
        "tagged_documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['Cleaned_Requirement'])]\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Memory (DM)\n",
        "model_dm = Doc2Vec(vector_size=20, window=4, min_count=1, workers=4, epochs=100, dm=1)\n",
        "model_dm.build_vocab(tagged_documents)\n",
        "model_dm.train(tagged_documents, total_examples=model_dm.corpus_count, epochs=model_dm.epochs)\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Bag of Words (DBOW)\n",
        "model_dbow = Doc2Vec(vector_size=20, window=2, min_count=1, workers=4, epochs=100, dm=0)\n",
        "model_dbow.build_vocab(tagged_documents)\n",
        "model_dbow.train(tagged_documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
        "\n",
        "# Transform documents into vectors using both trained Doc2Vec models\n",
        "document_vectors_dm = [model_dm.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "document_vectors_dbow = [model_dbow.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "\n",
        "# Concatenate the vectors from both models\n",
        "document_vectors_combined = [list(dm_vec) + list(dbow_vec) for dm_vec, dbow_vec in zip(document_vectors_dm, document_vectors_dbow)]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(document_vectors_combined, df['Type'], test_size=0.3, random_state= 10,stratify=df['Type'])\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "classifier = SVC(kernel='rbf',class_weight='balanced')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Combined DM and DBOW Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_GLE2Bey3r9",
        "outputId": "627907a8-81f7-4052-9aa2-327775e354d4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DM and DBOW Accuracy: 82.84%\n",
            "Accuracy: 0.8283828382838284\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.89      0.85      0.87       158\n",
            "         NFR       0.78      0.82      0.80       114\n",
            "          UX       0.70      0.74      0.72        31\n",
            "\n",
            "    accuracy                           0.83       303\n",
            "   macro avg       0.79      0.80      0.80       303\n",
            "weighted avg       0.83      0.83      0.83       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[134  20   4]\n",
            " [ 14  94   6]\n",
            " [  2   6  23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Model Training and Classification with Doc2Vec and Oversampling\n",
        "\n",
        "##### Split Data and Perform Oversampling\n",
        "- Split the data into training and testing sets.\n",
        "- Perform oversampling using SMOTE to balance the data.\n",
        "\n",
        "##### Train SVM Model with Balanced Data\n",
        "- Initialize and train the SVM model with the balanced data.\n",
        "\n",
        "##### Make Predictions and Evaluate Model\n",
        "- Make predictions on the test set.\n",
        "- Evaluate the model's performance using accuracy, classification report, and confusion matrix.\n",
        "\n",
        "##### Results\n",
        "- Print the class distribution after SMOTE oversampling, accuracy, classification report, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "SEaPiNGd1VBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag documents for Doc2Vec\n",
        "tagged_documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['Cleaned_Requirement'])]\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Memory (DM)\n",
        "model_dm = Doc2Vec(vector_size=20, window=4, min_count=1, workers=4, epochs=100, dm=1)\n",
        "model_dm.build_vocab(tagged_documents)\n",
        "model_dm.train(tagged_documents, total_examples=model_dm.corpus_count, epochs=model_dm.epochs)\n",
        "\n",
        "# Initialize and train the Doc2Vec model using Distributed Bag of Words (DBOW)\n",
        "model_dbow = Doc2Vec(vector_size=20, window=2, min_count=1, workers=4, epochs=100, dm=0)\n",
        "model_dbow.build_vocab(tagged_documents)\n",
        "model_dbow.train(tagged_documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
        "\n",
        "# Transform documents into vectors using both trained Doc2Vec models\n",
        "document_vectors_dm = [model_dm.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "document_vectors_dbow = [model_dbow.infer_vector(doc.split()) for doc in df['Cleaned_Requirement']]\n",
        "\n",
        "# Concatenate the vectors from both models\n",
        "document_vectors_combined = [list(dm_vec) + list(dbow_vec) for dm_vec, dbow_vec in zip(document_vectors_dm, document_vectors_dbow)]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(document_vectors_combined, df['Type'], test_size=0.3,stratify=df['Type'])\n",
        "\n",
        "\n",
        "# Instantiate the SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "# Instantiate Random sampling\n",
        "# ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Perform SMOTE oversampling\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the class distribution after oversampling\n",
        "print(\"Class distribution after SMOTE oversampling:\", Counter(y_resampled))\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "classifier = SVC(kernel='rbf',class_weight='balanced')\n",
        "classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Combined DM and DBOW Accuracy: {accuracy * 100:.2f}%')\n",
        "report = classification_report(y_test, y_pred, target_names=['F', 'NFR', 'UX'])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[\"F\", \"NFR\", \"UX\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XAqGakuvKXi",
        "outputId": "da0c8a76-b97e-4e69-a482-5eb26d393016"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after SMOTE oversampling: Counter({'NFR': 367, 'F': 367, 'UX': 367})\n",
            "Combined DM and DBOW Accuracy: 80.20%\n",
            "Accuracy: 0.801980198019802\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.88      0.82      0.85       158\n",
            "         NFR       0.77      0.82      0.79       114\n",
            "          UX       0.59      0.65      0.62        31\n",
            "\n",
            "    accuracy                           0.80       303\n",
            "   macro avg       0.75      0.76      0.75       303\n",
            "weighted avg       0.81      0.80      0.80       303\n",
            "\n",
            "Confusion Matrix:\n",
            "[[130  20   8]\n",
            " [ 15  93   6]\n",
            " [  3   8  20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IAcADyZLeOks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}